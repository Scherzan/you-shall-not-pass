bring in cyber and information security difference 
protect information and protect devices against attacks


Pip is the default package management tool for Python, allowing users to easily download, install, upgrade, and uninstall Python packages. 
Pip requires manual management of Python environments and dependencies, so it can become complex when managing many Python software packages.
Pyenv is used to manage Python versions, 
while Pipenv is used to manage packages, 
and Anaconda is a distribution of Python (think of it as a lazy package of Python).
The Conda package manager in Anaconda can easily manage Python environments and dependencies, 
and is more intelligent, making managing Python software packages easier.
In general, Pyenv is primarily used for managing the versions of Python and Pipenv is used for managing the dependent relationships of Python packages.




Background info from: https://blog.phylum.io/pick-a-python-lockfile-and-improve-security/
The story is not so simple for Python. A standard was proposed for a Python lockfile format, PEP 665, 
but was rejected due to “lukewarm reception from the community from the lack of source distribution support.
” This is a shame since malicious packages published to PyPI tend to rely on running code during package installation (e.g., via the setup.py file).

Phylum has identified and helped to remove a number of these malicious packages. 
Whether it’s crypto stealers or W4SP stealer malware, more of these supply chain attack attempts would be 
neutered by restricting lockfile based installations to wheels. True, attack vectors also include running 
malicious code during package import (e.g., via __init__.py files) and package execution (e.g., cloning a 
valid project and modifying existing or adding additional code to the modules). The adoption of PEP 665 
would have helped to prevent a specific and common attack vector.

         comparing pipenv and poetry:
         pipenv _> install pipenv _> creates pipfile and pipfile.lock
         -> easy ready to go
         antonia@antonia-ThinkPad-T480s:~/code/comparing-poetry-and-pipenv$ pipenv install matplotlib
Installing matplotlib...
Resolving matplotlib...
Added matplotlib to Pipfile's [packages] ...
✔ Installation Succeeded
Pipfile.lock (cba583) out of date, updating to (01afef)...
Locking [packages] dependencies...
Building requirements...
Resolving dependencies...
✔ Success!
Locking [dev-packages] dependencies...
Updated Pipfile.lock (50460ecdaff8dcf0091f387b4ecbc95550b5ca328e4967d787e06f328601afef)!
Installing dependencies from Pipfile.lock (01afef)...
To activate this project's virtualenv, run pipenv shell.
Alternatively, run a command inside the virtualenv with pipenv run.
         then do to run your files after all packages installed -> 
         pipenv run python main.py
         alternative run pipenv shel _> then python main.py same should work


einbringen lock file:
It doesn't prevent  
         14:38
         you from being a target of research, social  engineering, or getting solarwinded.
                 what are the features of lock file that are usefull?
         First, . A version  pin means each package is pinned to one specific  
         version. It's not a range of versions. It's not  unversioned. It's one specific version. What that  
         8:44
         means is that version that you're requesting  from PyPI is exactly the version. It's never  
         8:48
         going to change. If a new version is published,  you'll get the same old version until you bump it  
         8:53
         in your lockfile. -> how does this look like in pip and in poetry?


the package wasn't manipulated or changed  at some point. With the dependency confusion  
            9:13
            attack, we're installing the same version that we  thought we wanted, but it is giving us a different  
            9:18
            file from a different index. -> how does this look like in pip and in poetry?


#Let's look at some things  
#requirements dot text file. This  kind of looks like a web app. It's using Flask.  
#9:59
#Is this a lockfile? The answer is no. There  are no version pins. We had version ranges.  
#10:04
#That's good, but that's mostly for compatibility.  There are no hashes. That's probably not the  
#10:12
#full dependency tree. I know Flask has some  dependencies that weren't listed in that file.  
#10:21
#You might say I know how to fix this. Pip freeze.  I'm going to redirect the requirements to that  
#10:26
#text. Do not do this. This is an anti pattern.  If you're currently doing this, I'm going to show  
#10:31
#you a workflow that is a sort of better way to do  it. You do this and get something that looks like  
#10:38
#this. This is a lot. Maybe you're in a virtualenv  and you're pretty sure these are all the packages  
#10:43
#you need, but you have the potential to introduce  a lot of other stuff here. We have version pins  
#Version pins • Hashes X • Full dependency tree
#10:48
#here. We do not have hashes here. It is hard  to say if this is the full dependency tree.  
#10:53
#It probably is. But there's potentially other  stuff in there that I don't need that I installed  
#11:02
#by accident that's not a dependency in my  application and has the potential to increase the  
#11:08
#surface area. This isn't really a lockfile. How about pipenv install and pipenv lock?  
#11:24
#It gives me something like this. We can  see in here we have not only requests but  
#11:28
#the subdependencies of request. Is this a  lockfile? We can tell by the name, but yes,  
#11:35
#it has version pins in it, hashes, and the full  dependency tree. It looked at everything that got  
#11:42
#installed when you requested to install requests.  Then it put those all in the lockfile as well.  
#11:48
#Pipenv is pretty powerful, but it has its own  form of lockfile. I want you to use what I  
#An underused workflow Compiled Dependencies
#11:53
#think is an underused workflow, which I'll call  compiled dependencies. This is called pip tools,  
#12:00
#specifically the pip compile subtool of this.  You'll get a tool called pip compile. I think  
#12:07
#I said that right. This is really powerful because  it actually reuses it uses pip under the hood  
#12:13
#and so does pipenv, but this reuses the same file  formats that pip uses to declare dependencies.  
#12:24
#I'll give you an example of what this looks  like. This is one of the requirements files  
#12:29
#for warehouse, which is what we use to power the  Python Package Index. That's a web application. In  
#12:34
#this file here, this looked like that requirements  file way back when. We just sort of listed all the  
#12:41
#high level dependencies that I'm importing in this  file and none of the subdependencies. There's some  
#12:46
#version ranges for compatibility, but no pins.  I would tell pip compile to generate hashes  
#12:52
#and output its output into the requirements  dot text file. Then I would pass in this  
#12:56
#requirements dot env file. It produces a file  like this. It has a nice little header that  
#13:05
#says this file is auto generated. It has all the  dependencies I listed and their subdependencies  
#13:11
#and their hashes and a nice little  comment that tells me where it came from.  
#13:16
#I can see that's a dependency of boto3. I can  see this for every single thing in the log file.  
#13:23
#For warehouse, it looks kind of like this. The  powerful thing about this is it is using pip and  
#13:29
#pip's existing format. You might not have seen a  file like this, but pip has a nice feature where  
#13:38
#you can configure pipe to verify the hashes  for everything you install. In order to use  
#13:45
#hash checking mode, you have to hash check  every file. You don't have the potential for  
#13:49
#having a long requirements file where most things  are hashed, but you forgot to hash check every  
#13:59
#file. If you're not ready to adopt pipenv or want  to continue using vanilla pip, this is good.  
#14:16
#What kind of things can we prevent with  lockfiles? They present typo squatting. They are  
#What can we prevent with lockfiles?
#14:26
#set in the lockfile. You checked them when they  got committed that they were not a typo. This  
#14:32
#basically avoids the potential for typo squatting.  


whenever  there's a new version. It will go to the file  
#15:33
#where we've defined our requirements and change  that version pin. It will update the hashes. I'm  
#15:39
#trusting that Dependabot is getting these hashes  from PyPI and it hasn't been compromised. Again,  
#15:47
#introducing another component of my supply chain,  but the advantages are nice because I'm constantly  
#15:51
#being upgraded to the newest version.



https://owasp.org/www-community/Free_for_Open_Source_Application_Security_Tools




########## Keep Dependencies Updated [Manage Dependencies: Regularly Audit and Minimize Dependency Use] and use Updated Versions of python 
########## Upgrade, update, patch, Do not use the system standard version of Python, Review your dependency licenses
########## use latest versions ; use environments, Being careful is good, but segmentation is better
Outdated Python packages with known vulnerabilities can expose applications to attack. 
Keep dependencies like frameworks, libraries, and the Python interpreter up to date, 
especially for public-facing services.

Use dependency management tools like Poetry or Pipenv to lock versions yet still 
receive notifications of new releases and vulnerabilities. Monitor public vulnerability 
databases for issues in packages you rely on. When using third-party packages, 
favor well-known and maintained software from trusted sources like PyPI. 
Review code and activity for lesser-known modules.

########## use static code analyser / Regular Security Audits
##########
-> helps to find vulnerabilities etc.
Periodically conduct security audits and vulnerability assessments of your codebase. 
Utilize static code analysis tools like `bandit` to identify potential security flaws 
early in the development process.
-> tie it to secret handling: practice Properly Handle Secrets/ don't publish/Keep secrets secret
Have you ever heard the saying “the internet never forgets”? This is true for images and media, and it’s true for any secrets you might distribute with your code.

Developers sometimes hardcode information such as passwords, URLs with authentication information, and API keys to make testing easier. 
This is a bad practice, as such hardcoded secrets can be forgotten about and then committed to a code repo like GitHub or similar. 
Once this happens, those secrets will be included in databases or logs for anyone to see. Make sure that anything you upload—code, 
readme and configuration files, and especially plain text files—is free of secret information of any kind.

The second is the code you get from others. Open source or third-party code—including the dependencies in your code, 
both direct and transitive—is best handled by a software composition analysis (SCA) tool such as Black Duck®. 
This type of tool uncovers information about the packages you’re using, including their licensing, security, 
and operational risk state. 

########## Educate and Stay Updated



########## additions when publishing code ##########

Using both SAST and SCA tools helps uncover errors early in the software development life cycle, 
rather than later when they are more expensive and time-consuming to address. SATS tools -> siehe pubishing code

Adhering to Python security best practices means making sure that your code is free of vulnerabilities and bugs, 
so users and customers can use it without danger. There are two types of code to consider here. One is proprietary 
code—the code that you wrote. Proprietary code is best checked with a static application security testing (SAST) tool 
like Coverity®, which finds errors introduced during development that could make your code insecure.

and to publish alos adhere to licenses
Let’s start with license compliance. Projects are published under a variety of licenses and each has its own 
license obligations. However, regardless of license type, you need to fulfill all license obligations 
in order to avoid legal issues. You may want to avoid certain licenses entirely to avoid losing your 
intellectual property. Read our previous blog post for an more information on license compliance.


########## Additional Practices for publishing web apps (common app functionality) ###########

########## Input Validation Input sanitization [Beware of Input (Sanitize All Input and Use Parameterized Queries)]
Validation checks the integrity and correctness of input data, ensuring it meets specified criteria or constraints. 
Sanitization helps to remove potentially harmful or unexpected characters from input data, 
guarding against security vulnerabilities like SQL injection or cross-site scripting attacks.

One of the most important principles of secure coding is never to trust user input. 
Form input, query parameters, API calls, and even configuration files should all 
have their data checked before your software uses them. Let’s take an example of a 
login form for better understanding. For instance, think of a login form that requests 
a username and password. Before supplying the input to our authentication routines, 
it must be cleaned up:

import html 

username = html.escape(request.form['username']) 
password = html.escape(request.form['password']) 

# authenticate user 
authenticate (username, password)
This escapes any HTML special characters that could otherwise allow cross-site scripting attacks. We can also strip unwanted whitespace and truncate long inputs. In the same way, for numbers, dates, and other structured data, we can parse the input into the expected type and catch any exceptions:

import datetime
try:
date = datetime.datetime.strptime(request.form['date'], '%Y-%m-%d')
except ValueError:
# invalid date, handle error
Standard libraries like validators can also help validate common inputs like emails.

########## SQL Injection Protection, special case of sanitize user input? Yes quite common
When working with databases, one of the biggest risks is SQL injection. This allows attackers to run arbitrary SQL code and access unauthorized data. We should never concatenate user input directly into SQL queries to prevent this. Instead, use query parameterization provided by libraries like psycopg:

# unsafe
query = "SELECT * FROM users WHERE name = '" + username + "';"

# safe
query = "SELECT * FROM users WHERE name = %s;"
params = (username,)
cursor.execute(query, params)
The library handles proper escaping to prevent injection. Some ORM libraries like SQLAlchemy also automatically parameterize queries for safety.


########## Cryptography Best Practices Secure Password Handling secure / password storage/use cryptographie libraries
Never store passwords in plain text. Use cryptographic hashing algorithms 
Implement strong password policies and consider multi-factor authentication for added security layers.
Where possible, rely on tried-and-tested implementations from Python’s cryptography module instead 
of implementing custom cryptographic code. When hashing passwords, use a slow key derivation function like bcrypt, 
argon2 or scrypt to protect against brute force attacks if the hashes are stolen. For example:

from cryptography.hazmat.primitives import hashes
from cryptography.hazmat.primitives.kdf.pbkdf2 import PBKDF2HMAC
password = b'mypassword'
salt = os.urandom(16)
kdf = PBKDF2HMAC(algorithm=hashes.SHA256(), length=32, salt=salt, iterations=100000)
key = kdf.derive(password)
Random salts prevent dictionary attacks against common passwords. Slow key derivation prevents brute force attacks. Only use random data from `secrets` module for cryptography, not the basic `random` module. Always generate unique initialization vectors and use authenticated modes like GCM when using block ciphers.



##########
HTTPS and SSL/TLS
Any traffic sent over a network should use transport layer encryption via SSL/TLS. 
This prevents intermediaries from reading or modifying data in transit. Ensure any web applications or 
APIs enforce HTTPS connections and redirect any HTTP traffic. When using SSL sockets or other TLS APIs, 
require certificates to be valid and issued by a trusted certificate authority. Use certificates signed 
with SHA-256 rather than weaker MD5 or SHA-1 algorithms. Prioritize modern cipher suites like AES-256 and d
isable outdated ones like SSLv3. SSL Labs Server Test can help you evaluate the configuration.


##########

Logging and Auditing
Logging is crucial for security auditing and incident response. Ensure all login, 
access control failures, and input validation failures are logged with sufficient context. 
Use logging features appropriately — don’t log secrets or sensitive data!

Enable OS-level access logging for production systems. 
Centralize logs to a secured server with restricted access. 
Alert on unusual events like repeated failed logins or rate limiting. 
Log analysis tools like the ELK stack can help identify security incidents.

##########


Access Control
Limit access to data and functionality according to the principle of least privilege. 
Require authentication for accessing non-public endpoints. For example, an admin API in Django REST Framework can limit views to admin users:
Restrict access to sensitive information and APIs using role-based access control (RBAC).

from rest_framework import permissions
3. class AdminOnly(permissions.BasePermission):
4. def has_permission(self, request, view):
5. return request.user.is_staff
6. class AdminAPIView(APIView):
7. permission_classes = [AdminOnly]
File access policies should lock down sensitive data. Web applications should also implement CSRF protection.

##########


Secure Development Practices
Beyond just code, following secure processes during development can reduce risk:

Threat model new features and flows to identify vulnerabilities early
Perform security testing like penetration testing and code audits
Enable compiler protections like buffer overflow protection and memory sanitizers
Run services with principle of least privilege via containers or system accounts
Have an incident response plan for security events
Use type hints for runtime safety
Type hints like those in PEP 484 can catch bugs and reduce issues caused by Python’s dynamic typing. Tools like mypy can statically analyze type usage.
Use security-focused linter plugins
Flake8 and other linters have security-focused plugins to catch common issues. Use them in CI/CD pipelines.

##########:
Avoid deserialization of untrusted data / (De)serialize very cautiously
Be wary of vulnerabilities from deserializing untrusted data in formats like pickle. Where needed, only allow whitelisted types.



7. Keep Error Messages Minimal
Error messages often leak valuable information about your application’s internals, which attackers can exploit. Keep error messages concise and generic to avoid exposing sensitive data.


Set resource limits
Limit memory usage, CPU time, process count, request rate etc to protect against denial of service. For example, using the resource module.


Utilize OS-level security features.
Enable security modules like SELinux, AppArmor, and grsecurity on Linux to limit damage potential.


Rotate secrets periodically
Tokens, passwords, keys, and other secrets should be rotated periodically to limit impact of leaks/theft.

https://medium.com/@paritoshblogs/pyhton-projects-for-cybersecurity-e957401023fc
https://www.explainxkcd.com/wiki/index.php/792:_Password_Reuse
https://www.explainxkcd.com/wiki/index.php/538:_Security
file:///home/antonia/Downloads/OWASP_SCP_Quick_Reference_Guide.en-US.pdf










timin attack 

The first digit we guess is wrong,
so memcmp returns "false" after,
let's say, one tenth of a second.

We then change the first digit and try again.
And again. Until it takes memcmp two tenths
of a second to return a "false",

which means we hit the right first digit,
so it had to go on and consider the second one.

Again, we keep guessing
until it takes a moment longer,
then move on to the third,

and soon enough we get the entire password,
with just ten guesses per digit.
That is, 200 tries. Somewhat less than a trillion.

This is called a timing attack,
and more generally a side-channel attack.
When so-called side-channels,
byproducts of the system, if you will,
are used to gain some information on it.
This can be something like
how long it takes the system to reply,
but even crazier side-channels exist,
for example, the heat and sounds
that a CPU produces during encryption
can be used to infer its secret key
and crack its encryption.
Defending against side-channel attacks
is extremely tricky,
because they are, by definition,
collateral and unaccounted for,
and it's hard to protect something
when you don't even know it needs protecting.


The fixed implementation is the same as before,
except this time,
we have a result that equals "true",
so we assume the arrays are equal.
Then, we iterate over them,
and if we find any difference,
we set the result to "false".
But, and that's the important part,
we iterate over the entire array, no matter what,
and only then return the result,
so we don't leak information
about where exactly the arrays differ.
It's not the secure implementation
that requires ingenuity,
but how we define what secure means.

- passwordbased authentication works like this
- TIPS
- this is how a timing attack on a password would look like
- oter attacks -> example of richness of ways to get to sensitive information

"LESSON 04"
"TIPS ON PASSWORD USAGE - AUTHENTICATION"
Now that we know
how password-based authentication works,
and the common attacks against password systems,
I'd like to suggest some of my thoughts and advice
on ways you should and shouldn't use passwords.





what to do:
- always change default passwords of systems and devices you buy or set up
(specially important for internet connected things)


examples not change default apssword: 
This was painfully demonstrated in 2016,
when the Mirai botnet took over
millions of home routers and IP cameras,
whose owners didn't change
their default passwords.
Mirai used the commandeered devices
to overload major websites in what's called
a distributed denial-of-service attack, or DDoS.

attack _> crack into companies with user data and steal login data

tip
crack one site (getting into linkedin retreive user data -> all other accounts with same password compromised)
-> especialy those accounts very important all have different password.

tip -> difficult to remember
especially if follow tip2 -> use password manager
it is a smaller risk
if you use a password manager
than if you reuse passwords across sites. -> google password manager and find what suits you or use defaults in browsers
- remember to choose of one that can synchronize across devices 

tip on picking passwords: 
It's important to pick long
and hard to guess passwords,
that are not on any leaked password list.

- you want to remember for those where you login often
pick passwords
that are difficult for the attacker to guess,
yet reasonably easy for you to remember?

suggestion XKCD cartoon

who is still using password changes regularly?? -> self-defeating beacuase impractical and users default to easy passwords


engineer password checker well as application building permissions


let's consider some basic attacks
- guess passwords (trying out (autmated with scripts)) as we saw 
use lists of common passwords to try them: try common passwords with lists of common pw and defaults
-> good choice against poorly designed and maintained systems.
countermeasure ->  artificial delay
after each failed password check. to log in again

The delay should be short enough
not to annoy a user that made a typing mistake,
but should be long enough to make
a computerized attack impractical.
A delay of a few seconds is usually enough.
It's almost unnoticeable
when making one or two typos in a row,
but it's deadly if Malory wants to try
millions of guesses.
Moreover, in many systems,
if the number of failures exceeds the threshold,
say, of three, then the username is locked
and requires administrative action to unlock.

2. get hold of Alice's password.(tricking) social engineering

"social engineering" or "phishing".
often bait or scare you
into giving your password away.

3. steal password:
How would she do this?
when typing password -> password is transferred from the keyboard
to the target system.
with brief physical access to Alice's computer,
either little snooping device 
-> install a hardware  keylogger,
brief acces to pc over exploit -> software keylogger
log keys and send them to attacker



that is placed
between the keyboard cable
and the socket on the computer,
which records whatever is typed.

Malory would need to collect the keylogger later,
or engineer it to transmit
the recorded passwords to her.

This is not just Hollywood movie stuff.
You can buy reasonably priced keyloggers online.
This attack style is called
an "evil maid" attack.
Check it out on Wikipedia.

It's a good reason not to allow
unrestricted physical access to the server room
or to your desktop computer.

An alternative is to install a software keylogger.
If Malory can somehow run code
on Alice's computer, using an exploit,
this malicious code, or malware,
could log all the keys that Alice types
and send them to Malory.
The countermeasures are the same
as those against any malware:

countermeasures
To avoid, block and restrict code execution.

4. 
Finally, if the authenticated system is remote,
then the password Alice types
must travel across the network.
Malory may be able to snoop it in transit
using networking level attacks,
which we will learn about later in the course.
A countermeasure here is to use cryptography.
Alice, or Alice's computer
should not send the password
to the authenticating system as plaintext.
Passwords should only be sent
through an encrypted connection.



Even simpler, let's say we want to read a value,
just one byte, even, from restricted memory
that we aren't authorized to access.
How can we do that?
In C, accessing restricted memory
causes something called a page fault,
which you can think of as an exception.
The meltdown vulnerability is a very clever way
to do just that, access restricted memory.
But to understand how this is done,
there are two more things we need to cover:
Speculative execution and caches.
Speculative execution
is a common hardware optimization
where the CPU speculates what will happen next,
and executes some instructions ahead of time.
For example, in this code,
the CPU might speculate x
is indeed greater than zero,
and go ahead and fetch y from memory.
By the time it finishes evaluating
whether x is greater than zero or not,
it will have it handy.
If the speculation turns out to be wrong,
we can just discard the result,
but if it turns out to be right,
then we've gained a speed-up.
Going back to our example,
this means that the instruction
right after accessing the restricted memory
might get speculatively executed ahead of time,
but since accessing that memory
throws an exception,
this execution will never actually be applied,
and we have nothing to worry about. Yet.
Then there are caches.
You see, fetching something from memory,
that is, from RAM,
is actually quite slow by the CPU standards,
and can take around 100 nanoseconds.
So most CPUs have a smaller and faster memory unit
called a cache,
where they keep the recent
and most frequently used values,
so that the next time they're accessed,
they'd be available within one nanosecond.
If you want to stop the video and think
how this can be exploited, this is the time.
Otherwise, here's what we're gonna do.
First, we allocate an array
of 256 different numbers,
all the possible values a byte can have.
Then we access the restricted memory,
let's say its value is 2,
and use its value to index a particular cell,
so, the second cell.
This never actually happens,
since accessing that memory throws an exception,
but in fact, something does happen
behind the scenes.
You see, because of speculative execution, this
value does get fetched from memory ahead of time.
It's never made available, of course,
but it does get fetched.
And this brings us
to the last piece of the puzzle.
Because it gets fetched, it gets cached.
So now we have this value, 2,
readily available in our cache.
After handling the exception,
we simply iterate over this array,
and measure how long it takes to read each cell.
255 of the values
will have to be fetched from memory,
and take around 100 nanoseconds each.
But the single value
that was already fetched and cached
will be available within a nanosecond,
and this is precisely the value
of the restricted memory.
So even though we can't read it directly,
speculative execution, combined with a clever
cache-slash-timing attack,
lets us infer what the value was anyway,
which in turn might help us escape the sandbox,
and wreak all sorts of havoc.
That's meltdown,
or a simplified version of it, anyway.
We covered timing attacks
and side-channel attacks,
speculative execution and caches
just to see how all these pieces come together
into one amazing vulnerability.
Not surprisingly, there's no clear way
to mitigate it effectively.
Disabling speculative execution or caches
will result in an unacceptable slowdown.
Even though some patches addressing this
have been published,
you can imagine how painful it is
to update core components of the operating system,
let alone roll out new processors.
Replacing all of the vulnerable hardware out there
is near impossible.
This is often the case
with logical vulnerabilities.
If a system has a bug in its design,
there might be very little to do
except redesign the whole thing.
And in this case, the entire notion
of abstraction and encapsulation,
the theory at the core of computer science,
seems to have a bug in its design. Cool, huh?


cyber security additions:

what else can you do?:
- proper password hygene
- use https
- use encryption whenever transfering over internet
- be cautious on giving out personal information





lock files:
         for environment mangement lockfiles: 
         A lockfile can contain dependency version information that is valid across multiple platforms and Python interpreter versions. 
         Lockfiles are important because they allow for repeatable and deterministic installations. This is most beneficial for applications 
         living at the end of the dependency chain. It can also be useful for internal development and testing of libraries so that 
            other issues can be isolated and reproduced.
         -> many recommendations for uploading to pypi and packaging -> not go into this
         - go through Workflow tools assumption many of you use python for personal projects maby not yet into packaging and publishing tools but still upload code to github 
         and collaborate across public repos
         -> pipenv
         -> poetry
         -> pip-tools
         there are others: like hatch, pdm, rye.. not time to go into all. 
            What we can do: Use lockfiles because version pins, 
         this can f.e. mitigate squat attacks, avoids dependency confusion. 
         
hashes:
            Hashes verify the file downloaded from PyPI is the same as the version uploaded to PyPI hash computed when uploaded 
            verifies no manipulation/change 



start where maby many started: -> comparison of tools needed?

            - alternative pip-tools -> like to work with pip??
                     -> pip install -> installs into base _> need environments
            -> ok create environment with venv (for Python 3) 
                     python3 -m venv .venv
                     -> activate it now use pip as before
            -> problem? many packages _> make a list in requirements.txt (+ versions)
                     -> use. python3 -m pip install -r requirements.txt
                     and python3 -m pip freeze to get all packages you have installed -> others acn use it too
                     -> updateing becomes very cumbersome -> example in a blog. This loop of dependency conflicts may potentially continue for a long time, and get incredibly tiresome very quickly…
            (https://medium.com/packagr/using-pip-compile-to-manage-dependencies-in-your-python-packages-8451b21a949e)
                     
                     -> alternative: python -m pip install pip-tools
                     but then not have alist of requirements - dynamically want to tupdate your packages?
            
            same procedure for poetry:  


summarize to improve fundamentals site
from: https://owasp.org/www-project-developer-guide/draft/foundations/security_fundamentals/

CIA
CIA stands for Confidentiality, Integrity and Availability, and it is usually depicted as a triangle representing the strong bonds between its three tenets. This trio is considered the pillars of application security, with CIA described as a property of some data or of a process. Often CIA is extended with AAA: Authorization, Authentication and Auditing.

Confidentiality
Confidentiality is the protection of data against unauthorized disclosure; it is about ensuring that only those with the correct authorization can access the data and applies to both data at rest and to data in transit. Confidentiality is also related to the broader concept of data privacy.

Integrity
Integrity is about protecting data against unauthorized modification, or assuring data trustworthiness. The concept contains the notion of data integrity (data has not been changed accidentally or deliberately) and the notion of source integrity (data came from or was changed by a legitimate source).

Availability
Availability is about ensuring the presence of information or resources. This concept relies not just on the availability of the data itself, for example by using replication of data, but also on the protection of the services that provide access to the data, for example by using load balancing.

AAA
CIA is often extended with Authentication, Authorization and Auditing as these are closely linked to CIA concepts. 
CIA has a strong dependency on Authentication and Authorization; the confidentiality and integrity of sensitive data 
can not be assured without them. Auditing is added as it can provide the mechanism to ensure proof of any interaction with the system.

Authentication
Authentication is about confirming the identity of the entity that wants to interact with a secure system. 
For example the entity could be an automated client or a human actor; in either case authentication is required for a secure application.

Authorization
Authorization is about specifying access rights to secure resources (data, services, files, applications, etc). 
These rights describe the privileges or access levels related to the resources that are being secured.
 Authorization is usually preceded by successful authentication.

Auditing
Auditing is about keeping track of implementation-level events, as well as domain-level events taking place in a system. 
This helps to provide non-repudiation, which means that changes or actions on the protected system are undeniable. 
Auditing can provide not only technical information about the running system, but also proof that particular actions have been performed. 
The typical questions that are answered by auditing are “Who did What, When and potentially How?”

# 
also on secure development life cycle:
There are many OWASP tools and resources to help build security into the SDLC.

Requirements: this phase determines the functional, non-functional and security requirements for the application. 
Requirements should be revisited periodically and checked for completeness and validity, and it is worth considering various OWASP tools to help with this;
the Application Security Verification Standard (ASVS) provides developers with a list of requirements for secure development,
the Mobile Application Security project provides a security standard for mobile applications and SecurityRAT helps identify 
an initial set of security requirements.


Design: it is important to design security into the application - it is never too late to do this but the earlier the better and easier to do. OWASP provides two tools, Pythonic Threat Modeling and Threat Dragon, for threat modeling along with security gamification using Cornucopia.

Implementation: the OWASP Top 10 Proactive Controls project states that they are “the most important control and control categories that every architect and developer should absolutely, 100% include in every project” and this is certainly good advice. Implementing these controls can provide a high degree of confidence that the application or system will be reasonably secure. OWASP provides two libraries that can be incorporated in web applications, the Enterprise Security API (ESAPI) security control library and CSRFGuard to mitigate the risk of Cross-Site Request Forgery (CSRF) attacks, that help implement these proactive controls. In addition the OWASP Cheat Sheet Series is a valuable source of information and advice on all aspects of applications security.

Verification: OWASP provides a relatively large number of projects that help with testing and verification. This is the subject of a section in this Developer Guide, and the projects are listed at the end of this section.

other things incuded:
Training: development teams continually need security training. Although not part of the inner SDLC iterative loop training should still be factored into the project lifecycle. OWASP provides many training environments and materials - see the list at the end of this section.

Culture Building: a good security culture within a business organization will help greatly in keeping the applications and systems secure. There are many activities that all add up to create the security culture, the OWASP Security Culture project goes into more detail on these activities, and a good Security Champion program within the business is foundational to a good security posture. The OWASP Security Champions Guide provides guidance and material to create security champions within the development teams - ideally every team should have a security champion that has a special interest in security and has received further training, enabling the team to build security in.

Operation: the OWASP DevSecOps Guideline explains how to best implement a secure pipeline, using best practices and introducing automation tools to help ‘shift-left’. Refer to the DevSecOps Guideline for more information on any of the topics within DevSecOps and in particular sections on Operation.

Supply chain: attacks that leverage the supply chain can be devastating and there have been several high profile of products being successfully exploited. A Software Bill of Materials (SBOM) is the first step in avoiding these attacks and it is well worth using the OWASP CycloneDX full-stack Bill of Materials (BOM) standard for risk reduction in the supply chain. In addition the OWASP Dependency-Track project is a Continuous SBOM Analysis Platform which can help prevent these supply chain exploits by providing control of the SBOM.

Third party dependencies: keeping track of what third party libraries are included in the application, and what vulnerabilities they have, is easily automated. Many public repositories such as github and gitlab offer this service along with some commercial vendors. OWASP provides the Dependency-Check Software Composition Analysis (SCA) tool to track external libraries.

Application security testing: there are various types of security testing that can be automated on pull-request, merge or nightlies - or indeed manually but they are most powerful when automated. Commonly there is Static Application Security Testing (SAST), which analyses the code without running it, and Dynamic Application Security Testing (DAST), which applies input to the application while running it in a sandbox or other isolated environments. Interactive Application Security Testing (IAST) is designed to be run manually as well as being automated, and provides instant feedback on the tests as they are run.+

check for toolbox:
- login to pypi
- https://github.com/deepfence/ThreatMapper
- https://snyk.io/ free option 
- requires.io
- cheatsheet on storing passwords: https://cheatsheetseries.owasp.org/cheatsheets/Password_Storage_Cheat_Sheet.html

on environment requirements for security:
https://cheatsheetseries.owasp.org/cheatsheets/CI_CD_Security_Cheat_Sheet.html
as to ensure dependency references are immutable (CISA et al. 2022). Version pinning should be performed, 
the version chosen for pinning must be one that is known to be valid and secure, and the integrity of any 
package the system downloads should be validated by comparing its hash or checksum to a known good hash of 
the pinned package. The exact procedures to achieve this will vary depending on the project's underlying technology, 
but, in general, both version pinning and hash verification can be performed via a platform's "lock" or similar file 
(i.e. package-lock.json or Pipfile.lock). 


summarize to give vulnerabilities in open source
Coding vulnerabilities https://snyk.io/series/open-source-security/open-source-vulnerability-scanners/
-> check out the tools:
There are several common vulnerabilities that seasoned developers know of, but many open source projects have left unaddressed, such as:

SQL injections — Code permits alteration of SQL scripts, allowing attackers to manipulate or compromise information in databases by modifying parameters.

Cross-Site Scripting (XSS) — Compromised web pages enable attackers to inject client-side scripts that will be executed by other users who view the web page. The damage may include extracting cookies, exposing sensitive data, or defacing the existing website.

Insecure Direct Object References (IDOR) — An access control vulnerability where the code refers to an object directly through user-supplied input. This can be a name or ID supplied as a URL parameter, and might expose data unintentionally and give hackers useful information for other attacks on the site.

Cross-Site Request Forgery (CSRF) — When an end-user is forced or tricked into executing unwanted web requests for which they are currently authenticated. An attacker tricks the user into executing the actions of the attacker’s choosing. This can enable cyberthieves to modify or create profiles or user accounts for use in additional attacks.

Security misconfiguration — This vulnerability is often the result of using default configurations. Developers may not even know about these default settings, but they can allow attackers to access the system and retrieve important user information or even specific data regarding the application. This opens the door for future attacks that compromise those specific technologies.


Pip vs Conda: 
in python for data science commonly two packaging systems: pip and Conda.

-> we will ask how secure and which one to go for? 
(set the context linux and python, compare to conda-forge package repo (many channels available))


The starting point: which kind of dependencies?
The fundamental difference between pip and Conda packaging what kind of packages /service provide

Pip packages are Python libraries like NumPy or matplotlib.
Conda packages include Python libraries (NumPy or matplotlib), C libraries (libjpeg), 
and executables (like C compilers, and even the Python interpreter itself).


example: python with pandas and numpy and third party tool -> pip install numpy and pandas -> python install seperatly 
Python interpreter and gnuplot need to come from system packages, in this case Ubuntu’s packages.

With Conda, Python and gnuplot are just more Conda packages, no different than NumPy or Pandas. The environment.yml 
that corresponds (somewhat) to the requirements.txt we saw above will include all of these packages:

advantages conda:
In part it’s about portability and reproducibility.

Portability across operating systems: Instead of installing Python in three different ways on Linux, macOS, and Windows, you can use the same environment.yml on all three.
Reproducibility: It’s possible to pin almost the whole stack, from the Python interpreter upwards.
Consistent configuration: You don’t need to install system packages and Python packages in two different ways; (almost) everything can go in one file, the environment.yml.
But it also addresses another problem: how to deal with Python libraries that require compiled code.

problem:
For pure Python packages, this worked fine, and still does. But what happens when you need to compile some Rust or C or C++ or Fortran code as part of building the package?
Conda can do this because it’s not a packaging system only for Python code; it can just as easily package shared libraries or executables
ppi wheels and other solutions -> but more complex as conda

where get packages from?

tomorrow:
https://medium.com/@life-is-short-so-enjoy-it/what-is-difference-between-conda-and-poetry-when-to-use-conda-over-poetry-8743cc49ce4f